{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Up/downsampling data using temperature-scaled mixing\n",
    "\n",
    "Following this paper: \n",
    "- https://arxiv.org/pdf/1910.10683.pdf\n",
    "  - Scroll down to the \"Examples-proportional mixing\" section \n",
    "- https://github.com/HKUNLP/UnifiedSKG/blob/main/seq2seq_construction/meta_tuning.py#L23-L74\n",
    "\n",
    "to implement temperature scaled mixing. This is google's T5 paper and the algorithm refers to mixing datasets of different sizes. We are mixing labels of different sizes. The method is at the bottom of this notebook. P.S., if you're here for checkbox cleanup/analysis, I've moved it to checkbox_data_cleanup. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "\n",
    "# pd.set_option('display.max_rows', 120)\n",
    "\n",
    "df = pd.read_csv(\"../data/processed/case-data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Examples: 108804\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Direct Contact                            38878\n",
       "Collateral Contact                        24794\n",
       "Client Contact out of office              12677\n",
       "Client contact in office                  11446\n",
       "Attempted client contact                   4285\n",
       "                                          ...  \n",
       "Client rejected by available providers        2\n",
       "Medical detox not available                   2\n",
       "HACA                                          1\n",
       "Outpatient Treatment Program                  1\n",
       "Denied                                        1\n",
       "Name: DESCRIPTION, Length: 113, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts = df[\"DESCRIPTION\"].value_counts()\n",
    "print(\"Total Examples: %d\" % label_counts.sum()) \n",
    "label_counts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples proportional mixing\n",
    "\n",
    "\"...if we simply sample in proportion to each data set’s size, the vast majority of the data the model sees will be unlabeled, and it will undertrain on all of the supervised tasks... To get around this issue, we set an artificial “limit” on the data set sizes before computing the proportions.\"0\n",
    "\n",
    "Rewriting their formulas in terms of labels:\n",
    "\n",
    "If number of examples for each of our $N$ labels is $ e_n, n \\in \\{1, ..., N\\} $, then\n",
    "$$\n",
    "r_m = \\frac{min(e_m, K)}{\\sum min(e_n, K)}\n",
    "$$\n",
    "where $r_m$ is the probability of sampling an example with the $m$-th label during training, and $K$ is the arificial label size limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regardless of how we choose to combine and remove data, generic sampling methods can be written\n",
    "# For simplicity, lets use all_labels for now\n",
    "\n",
    "k = 1000\n",
    "total_labels = label_counts.apply(lambda x: min(x, k)).sum()\n",
    "weights = label_counts.apply(lambda x: min(x, k) / total_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index(\"DESCRIPTION\", inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weights contains $r_m$ for the $m$-th label. Now for each datapoint, we need to make the probability of picking it equal to $r_m / m_{total}$ where $m_{total}$ is the total number of samples with that label. $m_{total}$ is not $K$, the artificial limit. That's separate. \n",
    "\n",
    "So the sum of probabilities of picking samples with label $m$ will equal $r_m$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"class_weights\"] = weights\n",
    "df[\"class_totals\"] = label_counts\n",
    "df[\"sample_weights\"] = df[\"class_weights\"] / df[\"class_totals\"]\n",
    "df.reset_index(drop=False, inplace=True)\n",
    "\n",
    "# These should be equal\n",
    "# print(weights)\n",
    "# df.groupby(\"DESCRIPTION\")[\"sample_weights\"].sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attempted client contact                           5546\n",
       "Collateral Contact                                 5524\n",
       "Client contact in office                           5491\n",
       "Client Contact out of office                       5455\n",
       "No Show                                            5448\n",
       "                                                   ... \n",
       "Client rejected by available providers                9\n",
       "Outpatient Treatment Program                          8\n",
       "Denied                                                7\n",
       "HACA                                                  6\n",
       "Client not assigned DACC CSR due to court order       3\n",
       "Name: DESCRIPTION, Length: 113, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled = df.sample(frac=1, weights=\"sample_weights\", replace=True)\n",
    "df.drop(columns=[\"class_weights\", \"class_totals\", \"sample_weights\"], inplace=True)\n",
    "sampled[\"DESCRIPTION\"].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature Scaled Mixing\n",
    "Some summarization, some direct copying from the text: Temperature scaled mixing is almost identical, except each label's mixing rate $r_m$ is raised to the the power of $\\frac{1}{T}$ where $T$ is a temperaure scaling parameter. The rates are then renormalized so they sum to 1. \n",
    "\n",
    "\"When $T = 1$, this approach is equivalent to examples-proportional mixing and as $T$ increases the proportions become closer to equal mixing. We retain the data set size limit $K$ (applied to obtain $r_m$ before temperature scaling) but set it to a large value of $K = 2^{21}$. We use a large value of $K$ because increasing the temperature will decrease the mixing rate of the largest data\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temperature_scaled_mixing(df: pd.DataFrame, label_col: str, T, K=None, frac=1.0):\n",
    "    \"\"\"\n",
    "    df: the dataset to sample\n",
    "    label_col: the column containing the labels\n",
    "    T: The temperature parameter. When T=1, this is identical to examples-proportional mixing\n",
    "    K: The artificial size limit. If not provided, defaults to size of largest label set\n",
    "    frac: What fraction of the original df should the returned sampled df be. If 1, len(sampled.index) == len(df.index)\n",
    "    \"\"\"\n",
    "\n",
    "    label_counts = df[label_col].value_counts()\n",
    "    if not K:\n",
    "        K = label_counts.max() \n",
    "    total_labels = label_counts.apply(lambda x: min(x, K)).sum()\n",
    "    weights = label_counts.apply(lambda x: min(x, K) / total_labels)\n",
    "\n",
    "    weights = weights.pow(1.0 / T)\n",
    "    weights /= weights.sum()\n",
    "    \n",
    "    df.set_index(label_col, inplace=True)\n",
    "    df[\"class_weights\"] = weights\n",
    "    df[\"class_totals\"] = label_counts\n",
    "    df[\"sample_weights\"] = df[\"class_weights\"] / df[\"class_totals\"]\n",
    "    df.reset_index(label_col, inplace=True)\n",
    "    \n",
    "    sampled = df.sample(frac=frac, weights=\"sample_weights\", replace=True)\n",
    "    df.drop(columns=[\"class_weights\", \"class_totals\", \"sample_weights\"], inplace=True)\n",
    "    sampled.drop(columns=[\"class_weights\", \"class_totals\", \"sample_weights\"], inplace=True)\n",
    "\n",
    "    return sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Direct Contact                                     10347\n",
       "Client contact in office                           10315\n",
       "Collateral Contact                                 10261\n",
       "Client Contact out of office                       10260\n",
       "Attempted client contact                           10239\n",
       "                                                   ...  \n",
       "Partial: More than 1/2                                 5\n",
       "Denied                                                 5\n",
       "HACA                                                   4\n",
       "Client not assigned DACC CSR due to court order        2\n",
       "Outpatient Treatment Program                           2\n",
       "Name: DESCRIPTION, Length: 113, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_df = temperature_scaled_mixing(df, \"DESCRIPTION\", T=1, K=3000)\n",
    "sampled_df[\"DESCRIPTION\"].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
